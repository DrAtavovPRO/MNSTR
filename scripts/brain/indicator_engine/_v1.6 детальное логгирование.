#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Улучшенный модуль Indicator Engine для проекта MONSTER Trading System.
Реализует расширяемую архитектуру в стиле конструктора с глубоким контекстуальным анализом индикаторов.
"""

# ============================================================
# ИМПОРТЫ И ОПРЕДЕЛЕНИЯ ПУТЕЙ
# ============================================================

# Стандартные библиотеки Python
import os
import sys
import time
import json
import logging
import traceback
import functools
import concurrent.futures
from typing import Dict, List, Tuple, Optional, Union, Any, Set, Callable
from abc import ABC, abstractmethod
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict, namedtuple

# Определение путей для корректного импорта
current_file = os.path.abspath(__file__)
brain_dir = os.path.dirname(current_file)
core_dir = os.path.dirname(brain_dir)
scripts_dir = os.path.dirname(core_dir)
project_root = os.path.dirname(scripts_dir)

# Добавляем корневую директорию проекта в sys.path
sys.path.insert(0, project_root)

# Импорт научных библиотек с проверкой их наличия
try:
    import pandas as pd
    import numpy as np
    from scipy import signal
    from scipy.signal import argrelextrema
    from scipy import stats
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("ОШИБКА: pandas, numpy или scipy не установлены!")
    sys.exit(1)

# Импорт компонентов системы с обработкой возможных ошибок
try:
    # Импорт утилит логирования и мониторинга
    sys.path.append(os.path.join(project_root, 'scripts'))
    from utils.brain_logger import get_logger, send_telegram, log_execution_time
    from utils.monitor_system import monitor_system
    
    # Импорт конфигурационных параметров
    from config.brain.config import (
        # Базовые пути и настройки
        PATHS,
        TIMEFRAMES,
        PROCESSING,
        
        # Параметры для Indicator Engine
        INDICATOR_ENGINE,
        
        # Настройки индикаторов и паттернов
        INDICATORS,
        PATTERNS,
        DIVERGENCES,
        
        # Дополнительные настройки для торговых сигналов
        ORDERBOOK_ANALYSIS
    )
    
    LOGGER_IMPORTED = True
    
except ImportError as e:
    LOGGER_IMPORTED = False
    import logging
    logging.basicConfig(level=logging.ERROR)
    log_console = logging.getLogger("bootstrap")
    log_console.error(f"КРИТИЧЕСКАЯ ОШИБКА: Не удалось импортировать необходимые модули: {e}")
    log_console.error(f"Детали исключения: {traceback.format_exc()}")
    
# ============================================================
# НАСТРОЙКА ЛОГИРОВАНИЯ (ВСТАВИТЬ В НАЧАЛО ФАЙЛА)
# ============================================================

# ============================================================
# НАСТРОЙКА ЦЕНТРАЛИЗОВАННОГО ЛОГИРОВАНИЯ
# ============================================================

def setup_centralized_logging():
    """
    Настройка централизованной системы логирования.
    Создает единую структуру логов для всего приложения.
    """
    # Сброс всех существующих настроек логирования
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    
    # Установка базового уровня логирования
    logging.root.setLevel(logging.DEBUG)
    
    # Создание директории для логов
    log_dir = os.path.join('logs', 'brain', 'indicators')
    os.makedirs(log_dir, exist_ok=True)
    
    # Форматтеры для разных выводов
    console_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s: %(message)s')
    file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s [%(filename)s:%(lineno)d]: %(message)s')
    
    # Консольный вывод (INFO)
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(console_formatter)
    logging.root.addHandler(console_handler)
    
    # Общий файл логов (DEBUG)
    general_handler = logging.FileHandler(os.path.join(log_dir, 'indicator_engine.log'))
    general_handler.setLevel(logging.DEBUG)
    general_handler.setFormatter(file_formatter)
    logging.root.addHandler(general_handler)
    
    # Файл логов ошибок (ERROR)
    error_handler = logging.FileHandler(os.path.join(log_dir, 'errors.log'))
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(file_formatter)
    logging.root.addHandler(error_handler)

# Запускаем настройку логирования при импорте модуля
setup_centralized_logging()

# Функция для получения логгера без дополнительных обработчиков
def get_clean_logger(name):
    """
    Получает логгер для модуля без добавления дополнительных обработчиков.
    Использует настройки корневого логгера.
    
    Args:
        name: Имя логгера
        
    Returns:
        Настроенный логгер
    """
    return logging.getLogger(name)

# Основной логгер модуля
logger = get_clean_logger("indicator_engine")

# ============================================================
# КОНСТАНТЫ И ТИПЫ ДАННЫХ
# ============================================================

# Определение структуры для результатов анализа индикатора
IndicatorAnalysisResult = namedtuple('IndicatorAnalysisResult', [
    'indicator_name',           # Имя индикатора
    'current_value',            # Текущее значение
    'historical_context',       # Словарь с историческим контекстом
    'market_phases',            # Словарь с анализом по фазам рынка
    'signals',                  # Список сигналов
    'statistics',               # Словарь со статистикой
    'recommendation',           # Рекомендация (buy, sell, neutral)
    'confidence',               # Уверенность рекомендации (0.0 - 1.0)
    'metadata'                  # Дополнительные метаданные
])

# Типы рыночных условий
class MarketPhase(Enum):
    UPTREND = "uptrend"
    DOWNTREND = "downtrend"
    SIDEWAYS = "sideways"
    ACCUMULATION = "accumulation"
    DISTRIBUTION = "distribution"
    VOLATILE = "volatile"
    STABLE = "stable"
    UNKNOWN = "unknown"

# Типы сигналов
class SignalType(Enum):
    BUY = "buy"
    SELL = "sell"
    NEUTRAL = "neutral"
    STRONG_BUY = "strong_buy"
    STRONG_SELL = "strong_sell"
    EXIT = "exit"
    HOLD = "hold"

# ============================================================
# АБСТРАКТНЫЕ КЛАССЫ И ИНТЕРФЕЙСЫ
# ============================================================

class BaseIndicator(ABC):
    """
    Базовый абстрактный класс для всех индикаторов.
    Определяет интерфейс и общую функциональность для всех индикаторов.
    """
    
    def __init__(self, params: Dict = None, name: str = None):
        """
        Инициализирует индикатор.
        
        Args:
            params: Словарь с параметрами индикатора
            name: Имя индикатора (если не указано, используется имя класса)
        """
        self.params = params or {}
        self.name = name or self.__class__.__name__
        self.logger = get_clean_logger(f"indicator.{self.name.lower()}")
        
    @abstractmethod
    def calculate(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Рассчитывает индикатор и добавляет его в DataFrame.
        
        Args:
            df: DataFrame с данными (OHLCV)
            
        Returns:
            DataFrame с добавленными значениями индикатора
        """
        pass
    
    @abstractmethod
    def generate_signals(self, df: pd.DataFrame) -> List[Dict]:
        """
        Генерирует торговые сигналы на основе индикатора.
        
        Args:
            df: DataFrame с данными и рассчитанным индикатором
            
        Returns:
            Список словарей с сигналами
        """
        pass
    
    @abstractmethod
    def analyze_context(self, df: pd.DataFrame, timeframe: str) -> IndicatorAnalysisResult:
        """
        Выполняет контекстуальный анализ индикатора на основе всей истории.
        
        Args:
            df: DataFrame с данными и рассчитанным индикатором
            timeframe: Таймфрейм анализа ('5m', '15m', '1h', и т.д.)
            
        Returns:
            IndicatorAnalysisResult с результатами анализа
        """
        pass
    
    def get_cache_key(self, symbol: str, timeframe: str) -> str:
        """
        Создает уникальный ключ для кеширования результатов.
        
        Args:
            symbol: Символ монеты
            timeframe: Таймфрейм
            
        Returns:
            Строка-ключ для кеширования
        """
        param_hash = hash(frozenset(self.params.items())) if self.params else 0
        return f"{symbol}_{timeframe}_{self.name}_{param_hash}"
    
    def detect_market_phase(self, df: pd.DataFrame) -> MarketPhase:
        """
        Определяет текущую фазу рынка на основе исторических данных.
        
        Args:
            df: DataFrame с данными OHLCV
            
        Returns:
            MarketPhase: Определенная фаза рынка
        """
        try:
            if len(df) < 20:
                return MarketPhase.UNKNOWN
                
            # Рассчитываем тренд за последние 20 периодов
            close_prices = df['close'].iloc[-20:]
            price_change = (close_prices.iloc[-1] - close_prices.iloc[0]) / close_prices.iloc[0]
            
            # Рассчитываем волатильность
            volatility = close_prices.pct_change().std()
            
            # Рассчитываем объемный тренд, если доступны данные об объеме
            volume_trend = 0
            if 'volume' in df.columns:
                volume = df['volume'].iloc[-20:]
                volume_change = (volume.iloc[-1] - volume.iloc[0]) / volume.iloc[0] if volume.iloc[0] > 0 else 0
                volume_trend = volume_change
            
            # Определяем фазу рынка
            if price_change > 0.05 and volume_trend > 0:
                return MarketPhase.UPTREND
            elif price_change < -0.05 and volume_trend < 0:
                return MarketPhase.DOWNTREND
            elif volatility > 0.03:
                return MarketPhase.VOLATILE
            elif volatility < 0.01:
                return MarketPhase.STABLE
            elif abs(price_change) < 0.02 and volume_trend > 0.1:
                return MarketPhase.ACCUMULATION
            elif abs(price_change) < 0.02 and volume_trend < -0.1:
                return MarketPhase.DISTRIBUTION
            elif abs(price_change) < 0.03:
                return MarketPhase.SIDEWAYS
            else:
                return MarketPhase.UNKNOWN
        
        except Exception as e:
            self.logger.error(f"Ошибка при определении фазы рынка: {e}")
            return MarketPhase.UNKNOWN
    
    def evaluate_indicator_performance(self, df: pd.DataFrame, indicator_column: str) -> Dict:
        """
        Оценивает историческую эффективность индикатора.
        
        Args:
            df: DataFrame с данными и рассчитанным индикатором
            indicator_column: Имя столбца с индикатором
            
        Returns:
            Dict: Словарь со статистикой эффективности
        """
        try:
            if indicator_column not in df.columns or len(df) < 30:
                return {"status": "insufficient_data"}
            
            # Базовая статистика
            stats_data = {
                "mean": float(df[indicator_column].mean()),
                "median": float(df[indicator_column].median()),
                "std": float(df[indicator_column].std()),
                "min": float(df[indicator_column].min()),
                "max": float(df[indicator_column].max()),
                "current_percentile": float(stats.percentileofscore(
                    df[indicator_column].dropna(), df[indicator_column].iloc[-1]
                )),
                "status": "success"
            }
            
            return stats_data
            
        except Exception as e:
            self.logger.error(f"Ошибка при оценке производительности индикатора: {e}")
            return {"status": "error", "message": str(e)}


class IndicatorRegistry:
    """
    Реестр индикаторов для централизованного управления и доступа к индикаторам.
    """
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(IndicatorRegistry, cls).__new__(cls)
            cls._instance.indicators = {}
            cls._instance.logger = get_clean_logger("indicator_registry")
        return cls._instance
    
    def register(self, indicator_class: type, name: str = None, params: Dict = None) -> None:
        """
        Регистрирует индикатор в реестре.
        
        Args:
            indicator_class: Класс индикатора
            name: Имя для регистрации (если None, используется имя класса)
            params: Параметры для инициализации индикатора
        """
        name = name or indicator_class.__name__
        
        try:
            indicator_instance = indicator_class(params=params, name=name)
            self.indicators[name] = indicator_instance
            self.logger.info(f"Индикатор {name} успешно зарегистрирован")
        except Exception as e:
            self.logger.error(f"Ошибка при регистрации индикатора {name}: {e}")
    
    def get(self, name: str) -> Optional[BaseIndicator]:
        """
        Получает индикатор по имени.
        
        Args:
            name: Имя индикатора
            
        Returns:
            Экземпляр индикатора или None, если индикатор не найден
        """
        return self.indicators.get(name)
    
    def get_all(self) -> Dict[str, BaseIndicator]:
        """
        Получает все зарегистрированные индикаторы.
        
        Returns:
            Словарь с индикаторами {имя: экземпляр}
        """
        return self.indicators
    
    def has_indicator(self, name: str) -> bool:
        """
        Проверяет, зарегистрирован ли индикатор.
        
        Args:
            name: Имя индикатора
            
        Returns:
            True, если индикатор зарегистрирован, иначе False
        """
        return name in self.indicators


# ============================================================
# УТИЛИТЫ КЕШИРОВАНИЯ, ХРАНЕНИЯ И ОБРАБОТКИ
# ============================================================

class DataCache:
    """
    Класс для кеширования результатов расчетов.
    Поддерживает кеширование в памяти и опционально в Redis.
    """
    
    def __init__(self, use_redis: bool = False, redis_config: Dict = None):
        """
        Инициализирует кеш данных.
        
        Args:
            use_redis: Использовать ли Redis для кеширования
            redis_config: Конфигурация Redis (хост, порт, база данных)
        """
        self.memory_cache = {}
        self.use_redis = use_redis
        self.logger = get_clean_logger("data_storage")
        
        if use_redis:
            try:
                import redis
                redis_config = redis_config or {}
                # Подключение к Redis
                self.redis_client = redis.Redis(
                    host=redis_config.get('host', 'localhost'),
                    port=redis_config.get('port', 6379),
                    db=redis_config.get('db', 0)
                )
                self.logger.info("Redis подключен успешно")
            except ImportError:
                self.logger.warning("Модуль redis не установлен. Используется только кеширование в памяти.")
                self.use_redis = False
            except Exception as e:
                self.logger.error(f"Ошибка при подключении к Redis: {e}")
                self.use_redis = False
    
    def get(self, key: str) -> Any:
        """
        Получает данные из кеша.
        
        Args:
            key: Ключ для поиска в кеше
            
        Returns:
            Значение из кеша или None, если ключа нет
        """
        # Сначала проверяем в памяти
        if key in self.memory_cache:
            return self.memory_cache[key]
        
        # Затем проверяем в Redis, если он используется
        if self.use_redis:
            try:
                import pickle
                data = self.redis_client.get(key)
                if data:
                    return pickle.loads(data)
            except Exception as e:
                self.logger.error(f"Ошибка при получении данных из Redis: {e}")
        
        return None
    
    def set(self, key: str, value: Any, ttl: int = None) -> None:
        """
        Сохраняет данные в кеш.
        
        Args:
            key: Ключ для сохранения в кеше
            value: Значение для сохранения
            ttl: Время жизни в секундах (только для Redis)
        """
        # Сохраняем в памяти
        self.memory_cache[key] = value
        
        # Сохраняем в Redis, если он используется
        if self.use_redis:
            try:
                import pickle
                self.redis_client.set(key, pickle.dumps(value))
                if ttl:
                    self.redis_client.expire(key, ttl)
            except Exception as e:
                self.logger.error(f"Ошибка при сохранении данных в Redis: {e}")


class DataStorage:
    """
    Класс для работы с хранилищем данных.
    Поддерживает сохранение в JSON и опционально в Parquet.
    """
    
    def __init__(self, base_path: str, use_parquet: bool = False):
        """
        Инициализирует хранилище данных.
        
        Args:
            base_path: Базовый путь к данным
            use_parquet: Использовать ли Parquet для хранения данных
        """
        self.base_path = base_path
        self.use_parquet = use_parquet
        self.logger = get_clean_logger("data_storage")
        
        if use_parquet:
            try:
                import pyarrow as pa
                import pyarrow.parquet as pq
                self.pa = pa
                self.pq = pq
                self.logger.info("Parquet поддержка включена")
            except ImportError:
                self.logger.warning("Модули pyarrow и/или pyarrow.parquet не установлены. Используется JSON.")
                self.use_parquet = False
    
    def save_indicators(self, symbol: str, timeframe: str, data: Dict) -> None:
        """
        Сохраняет результаты расчета индикаторов.
        
        Args:
            symbol: Символ монеты
            timeframe: Таймфрейм
            data: Словарь с результатами расчета индикаторов
        """
        # Создаем директорию, если она не существует
        indicators_dir = os.path.join(self.base_path, "indicators", "current", timeframe)
        os.makedirs(indicators_dir, exist_ok=True)
        
        # Путь к файлу результатов
        file_path = os.path.join(indicators_dir, f"{symbol}_{timeframe}")
        
        if self.use_parquet:
            try:
                # Преобразование в формат, подходящий для Parquet
                flat_data = self._flatten_dict(data)
                table = self.pa.Table.from_pydict(flat_data)
                self.pq.write_table(table, f"{file_path}.parquet")
                self.logger.info(f"Данные сохранены в Parquet: {file_path}.parquet")
            except Exception as e:
                self.logger.error(f"Ошибка при сохранении данных в Parquet: {e}")
                # Если возникла ошибка, сохраняем в JSON как запасной вариант
                self._save_to_json(f"{file_path}.json", data)
        else:
            # Сохранение в JSON
            self._save_to_json(f"{file_path}.json", data)
    
    def _save_to_json(self, file_path: str, data: Dict) -> None:
        """
        Сохраняет данные в JSON файл.
        
        Args:
            file_path: Путь к файлу
            data: Данные для сохранения
        """
        try:
            # Создаем директорию, если она не существует
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # Сохраняем данные в JSON
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, default=self._json_serializer)
            
            self.logger.info(f"Данные успешно сохранены в {file_path}")
        except Exception as e:
            self.logger.error(f"Ошибка при сохранении в JSON: {e}")
            self.logger.debug(traceback.format_exc())

    def _json_serializer(self, obj):
        """
        Сериализатор для JSON, который может обрабатывать нестандартные типы.
        """
        if isinstance(obj, (pd.Timestamp, datetime)):
            return obj.isoformat()
        elif isinstance(obj, (np.int64, np.int32, np.int16, np.int8)):
            return int(obj)
        elif isinstance(obj, (np.float64, np.float32, np.float16)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, pd.Series):
            return obj.to_dict()
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict(orient='records')
        elif isinstance(obj, Enum):
            return obj.value
        elif hasattr(obj, '__dict__'):
            return obj.__dict__
        else:
            return str(obj)
    
    def load_indicators(self, symbol: str, timeframe: str) -> Optional[Dict]:
        """
        Загружает сохраненные результаты индикаторов.
        
        Args:
            symbol: Символ монеты
            timeframe: Таймфрейм
            
        Returns:
            Словарь с результатами расчета индикаторов или None, если файл не найден
        """
        # Путь к файлу результатов
        indicators_dir = os.path.join(self.base_path, "indicators", "current", timeframe)
        file_path = os.path.join(indicators_dir, f"{symbol}_{timeframe}")
        
        try:
            if self.use_parquet and os.path.exists(f"{file_path}.parquet"):
                # Загрузка из Parquet
                table = self.pq.read_table(f"{file_path}.parquet")
                flat_dict = {col: table[col].to_pylist() for col in table.column_names}
                self.logger.info(f"Данные успешно загружены из Parquet: {file_path}.parquet")
                return self._unflatten_dict(flat_dict)
            elif os.path.exists(f"{file_path}.json"):
                # Загрузка из JSON
                with open(f"{file_path}.json", 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.logger.info(f"Данные успешно загружены из JSON: {file_path}.json")
                return data
            else:
                self.logger.debug(f"Файл с индикаторами для {symbol} ({timeframe}) не найден")
                return None
        except Exception as e:
            self.logger.error(f"Ошибка при загрузке индикаторов для {symbol} ({timeframe}): {e}")
            return None
    
    def _flatten_dict(self, d: Dict, parent_key: str = '') -> Dict:
        """
        Преобразует вложенный словарь в плоскую структуру для сохранения в Parquet.
        
        Args:
            d: Вложенный словарь
            parent_key: Ключ родительского элемента
            
        Returns:
            Плоский словарь с составными ключами
        """
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}.{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(self._flatten_dict(v, new_key).items())
            else:
                items.append((new_key, v))
        return dict(items)
    
    def _unflatten_dict(self, d: Dict) -> Dict:
        """
        Преобразует плоскую структуру обратно во вложенный словарь после загрузки из Parquet.
        
        Args:
            d: Плоский словарь с составными ключами
            
        Returns:
            Вложенный словарь
        """
        result = {}
        for key, value in d.items():
            parts = key.split('.')
            current = result
            for part in parts[:-1]:
                if part not in current:
                    current[part] = {}
                current = current[part]
            current[parts[-1]] = value
        return result


class ParallelProcessor:
    """
    Класс для параллельной обработки данных с использованием ThreadPoolExecutor.
    """
    
    def __init__(self, max_workers: int = None, chunk_size: int = None):
        """
        Инициализирует процессор.
        
        Args:
            max_workers: Максимальное количество рабочих потоков
            chunk_size: Размер пакета для обработки
        """
        self.max_workers = max_workers
        self.chunk_size = chunk_size
        self.logger = get_clean_logger("parallel_processor")
    
    def process_symbols(self, symbols: List[str], process_func, **kwargs) -> Dict:
        """
        Обрабатывает список символов параллельно.
        
        Args:
            symbols: Список символов для обработки
            process_func: Функция для обработки пакета символов
            **kwargs: Дополнительные параметры для функции обработки
            
        Returns:
            Словарь с результатами обработки
        """
        start_time = time.time()
        symbols_count = len(symbols)
        
        self.logger.info(f"Начало параллельной обработки {symbols_count} символов")
        
        # Подготовка чанков для обработки
        if self.chunk_size and symbols_count > self.chunk_size:
            chunks = [symbols[i:i+self.chunk_size] for i in range(0, symbols_count, self.chunk_size)]
            self.logger.info(f"Разделение на {len(chunks)} пакетов по {self.chunk_size} символов")
        else:
            chunks = [symbols]
            self.logger.info(f"Обработка всех символов в одном пакете")
        
        # Определение оптимального числа рабочих потоков
        workers = min(self.max_workers or os.cpu_count(), len(chunks))
        self.logger.info(f"Доступно {os.cpu_count()} процессорных ядер, используется {workers} {'поток' if workers == 1 else 'потоков'}")
        
        results = {
            'success': True,
            'total_symbols': len(symbols),
            'successful_symbols': 0,
            'failed_symbols': 0,
            'total_signals': 0,
            'results': {}
        }
        
        self.logger.info(f"Начало параллельной обработки {len(symbols)} символов в {len(chunks)} пакетах")
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for chunk in chunks:
                future = executor.submit(process_func, chunk, **kwargs)
                futures.append(future)
            
            for future in concurrent.futures.as_completed(futures):
                try:
                    chunk_result = future.result()
                    
                    # Объединение результатов
                    results['successful_symbols'] += chunk_result.get('successful_symbols', 0)
                    results['failed_symbols'] += chunk_result.get('failed_symbols', 0)
                    results['total_signals'] += chunk_result.get('total_signals', 0)
                    
                    if 'results' in chunk_result:
                        results['results'].update(chunk_result['results'])
                        
                except Exception as e:
                    self.logger.error(f"Ошибка при обработке чанка: {e}")
                    self.logger.debug(traceback.format_exc())
                    results['success'] = False
        
        execution_time = time.time() - start_time
        results['execution_time'] = execution_time
        
        self.logger.info(f"Параллельная обработка завершена за {execution_time:.2f} сек. "
                         f"Успешно: {results['successful_symbols']}/{results['total_symbols']}")
        
        return results


# ============================================================
# РЕАЛИЗАЦИЯ RSI С КОНТЕКСТУАЛЬНЫМ АНАЛИЗОМ
# ============================================================

class RSI(BaseIndicator):
    """
    Индикатор Relative Strength Index (RSI) с расширенным контекстуальным анализом.
    
    RSI измеряет скорость и изменение ценовых движений, анализируя соотношение средних
    положительных и отрицательных изменений цены за определенный период.
    
    Расширенный анализ включает:
    - Анализ исторических уровней RSI
    - Оценку эффективности сигналов RSI в различных рыночных условиях
    - Анализ дивергенций RSI и цены
    - Адаптивные уровни перекупленности/перепроданности на основе исторических данных
    """
    
    def __init__(self, params: Dict = None, name: str = None):
        """
        Инициализирует индикатор RSI с расширенными возможностями анализа.
        
        Args:
            params: Словарь с параметрами индикатора
            name: Имя индикатора (если не указано, используется имя класса)
        """
        # Вызываем конструктор родительского класса
        super().__init__(params, name)
        
        # Инициализируем параметры
        self.period = self.params.get('period', 14)
        self.overbought = self.params.get('overbought', 70)
        self.oversold = self.params.get('oversold', 30)
        self.adaptive_levels = self.params.get('adaptive_levels', True)
        self.context_window = self.params.get('context_window', 90)
        
        # Логируем параметры для отладки
        self.logger.debug(f"RSI инициализирован с параметрами: period={self.period}, "
                         f"overbought={self.overbought}, oversold={self.oversold}, "
                         f"adaptive_levels={self.adaptive_levels}")

    def calculate(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Рассчитывает RSI и добавляет его в DataFrame.
        
        Формула:
            RSI = 100 - (100 / (1 + RS))
            где RS = Средний прирост / Средние потери
        
        Args:
            df: DataFrame с данными (должен содержать столбец 'close')
            
        Returns:
            DataFrame с добавленным столбцом 'rsi'
        """
        self.logger.info(f"Начинаем расчет RSI с периодом {self.period}")
        self.logger.debug(f"Размер входного DataFrame: {len(df)} строк, столбцы: {list(df.columns)}")
        
        start_time = time.time()

        if 'close' not in df.columns:
            self.logger.error("DataFrame не содержит столбец 'close', необходимый для расчета RSI")
            raise ValueError("DataFrame должен содержать столбец 'close' для расчета RSI")
        
        try:
            # Логируем первые несколько значений цены закрытия
            self.logger.debug(f"Первые 5 значений цены закрытия: {df['close'].head(5).tolist()}")
            
            # Оптимизированный расчет RSI с использованием векторизации Pandas
            self.logger.debug("Расчет изменений цены закрытия (close_delta)")
            close_delta = df['close'].diff()
            self.logger.debug(f"Первые 5 значений close_delta: {close_delta.head(5).tolist()}")
            
            # Получаем положительные и отрицательные изменения
            self.logger.debug("Разделение на положительные и отрицательные изменения")
            up = close_delta.where(close_delta > 0, 0)
            down = -close_delta.where(close_delta < 0, 0)
            
            # Логируем первые несколько значений up и down
            self.logger.debug(f"Первые 5 значений up: {up.head(5).tolist()}")
            self.logger.debug(f"Первые 5 значений down: {down.head(5).tolist()}")
            
            # Рассчитываем среднее значение положительных и отрицательных изменений
            self.logger.debug(f"Расчет экспоненциальных средних с периодом {self.period}")
            avg_gain = up.ewm(com=self.period-1, min_periods=self.period).mean()
            avg_loss = down.ewm(com=self.period-1, min_periods=self.period).mean()
            
            # Защита от деления на ноль
            avg_loss = avg_loss.where(avg_loss != 0, 0.00001)
            
            # Рассчитываем relative strength (RS)
            self.logger.debug("Расчет Relative Strength (RS)")
            rs = avg_gain / avg_loss
            
            # Рассчитываем RSI
            self.logger.debug("Расчет RSI на основе RS")
            df['rsi'] = 100 - (100 / (1 + rs))
            
            # Логируем первые и последние значения RSI
            self.logger.debug(f"Первые 5 значений RSI: {df['rsi'].head(5).tolist()}")
            self.logger.debug(f"Последние 5 значений RSI: {df['rsi'].tail(5).tolist()}")
            
            # Если используются адаптивные уровни, рассчитываем их
            if self.adaptive_levels and len(df) > 30:
                self.logger.debug("Расчет адаптивных уровней RSI")
                # Рассчитываем исторические перцентили RSI
                df['rsi_80_percentile'] = df['rsi'].rolling(window=30).apply(
                    lambda x: np.percentile(x, 80) if len(x.dropna()) > 0 else 70
                )
                df['rsi_20_percentile'] = df['rsi'].rolling(window=30).apply(
                    lambda x: np.percentile(x, 20) if len(x.dropna()) > 0 else 30
                )
                
                # Заполняем NaN значения для первых строк
                df['rsi_80_percentile'] = df['rsi_80_percentile'].fillna(70)
                df['rsi_20_percentile'] = df['rsi_20_percentile'].fillna(30)
                
                self.logger.debug(f"Средний верхний адаптивный уровень: {df['rsi_80_percentile'].mean()}")
                self.logger.debug(f"Средний нижний адаптивный уровень: {df['rsi_20_percentile'].mean()}")
            
            # Заполняем NaN на 50 - нейтральное значение для RSI
            df['rsi'] = df['rsi'].fillna(50)
            
            # Добавляем столбец для скорости изменения RSI (для определения импульса)
            df['rsi_change'] = df['rsi'].diff(3)
            
            self.logger.info("Расчет RSI успешно завершен")
            
            # Логируем базовую статистику результатов
            self.logger.info(f"Статистика RSI: min={df['rsi'].min():.2f}, max={df['rsi'].max():.2f}, mean={df['rsi'].mean():.2f}")
            self.logger.info(f"Текущее значение RSI: {df['rsi'].iloc[-1]:.2f}")
            self.logger.debug(f"Расчет RSI заняла {time.time() - start_time:.4f} секунд")

            return df
        except Exception as e:
            self.logger.error(f"Ошибка при расчете RSI: {e}")
            self.logger.debug(traceback.format_exc())
            # В случае ошибки добавляем пустой столбец RSI
            df['rsi'] = [None] * len(df)
            return df
    
    def generate_signals(self, df: pd.DataFrame) -> List[Dict]:
        """
        Генерирует торговые сигналы на основе RSI.
        
        Сигналы:
        - Перепроданность (RSI < oversold): возможная покупка
        - Перекупленность (RSI > overbought): возможная продажа
        - Пересечение нейтрального уровня 50
        - Дивергенции RSI и цены
        
        Args:
            df: DataFrame с данными и рассчитанным RSI
            
        Returns:
            Список словарей с сигналами
        """
        signals = []
        
        if 'rsi' not in df.columns:
            self.logger.warning("Столбец 'rsi' не найден в DataFrame. Сигналы не сгенерированы.")
            return signals
        
        try:
            # Определяем уровни перекупленности/перепроданности
            if self.adaptive_levels and 'rsi_80_percentile' in df.columns:
                overbought_level = df['rsi_80_percentile']
                oversold_level = df['rsi_20_percentile']
            else:
                overbought_level = pd.Series([self.overbought] * len(df), index=df.index)
                oversold_level = pd.Series([self.oversold] * len(df), index=df.index)
            
            # 1. Сигналы перепроданности
            oversold_condition = df['rsi'] < oversold_level
            if oversold_condition.any():
                # Находим точки пересечения уровня перепроданности снизу вверх
                crosses_up = (df['rsi'].shift(1) < oversold_level.shift(1)) & (df['rsi'] >= oversold_level)
                
                for idx in df.index[crosses_up]:
                    signals.append({
                        'indicator': 'RSI',
                        'signal_type': SignalType.BUY.value,
                        'timestamp': str(idx) if not isinstance(idx, str) else idx,
                        'price': df.loc[idx, 'close'],
                        'strength': min(1.0, 1 - (df.loc[idx, 'rsi'] / float(oversold_level.loc[idx]))),
                        'description': f'RSI пересек уровень перепроданности {float(oversold_level.loc[idx]):.1f} снизу вверх',
                        'value': float(df.loc[idx, 'rsi'])
                    })
            
            # 2. Сигналы перекупленности
            overbought_condition = df['rsi'] > overbought_level
            if overbought_condition.any():
                # Находим точки пересечения уровня перекупленности сверху вниз
                crosses_down = (df['rsi'].shift(1) > overbought_level.shift(1)) & (df['rsi'] <= overbought_level)
                
                for idx in df.index[crosses_down]:
                    signals.append({
                        'indicator': 'RSI',
                        'signal_type': SignalType.SELL.value,
                        'timestamp': str(idx) if not isinstance(idx, str) else idx,
                        'price': df.loc[idx, 'close'],
                        'strength': min(1.0, (df.loc[idx, 'rsi'] - float(overbought_level.loc[idx])) / (100 - float(overbought_level.loc[idx]))),
                        'description': f'RSI пересек уровень перекупленности {float(overbought_level.loc[idx]):.1f} сверху вниз',
                        'value': float(df.loc[idx, 'rsi'])
                    })
            
            # 3. Сигналы пересечения центральной линии (50)
            crosses_above_50 = (df['rsi'].shift(1) < 50) & (df['rsi'] > 50)
            crosses_below_50 = (df['rsi'].shift(1) > 50) & (df['rsi'] < 50)
            
            for idx in df.index[crosses_above_50]:
                signals.append({
                    'indicator': 'RSI',
                    'signal_type': SignalType.BUY.value,
                    'timestamp': str(idx) if not isinstance(idx, str) else idx,
                    'price': df.loc[idx, 'close'],
                    'strength': 0.5 + min(0.5, abs(df.loc[idx, 'rsi'] - 50) / 50),
                    'description': 'RSI пересек центральный уровень 50 снизу вверх',
                    'value': float(df.loc[idx, 'rsi'])
                })
                
            for idx in df.index[crosses_below_50]:
                signals.append({
                    'indicator': 'RSI',
                    'signal_type': SignalType.SELL.value,
                    'timestamp': str(idx) if not isinstance(idx, str) else idx,
                    'price': df.loc[idx, 'close'],
                    'strength': 0.5 + min(0.5, abs(df.loc[idx, 'rsi'] - 50) / 50),
                    'description': 'RSI пересек центральный уровень 50 сверху вниз',
                    'value': float(df.loc[idx, 'rsi'])
                })
            
            # 4. Поиск дивергенций (с полноценной проверкой трендов)
            self._detect_divergences(df, signals)
            
        except Exception as e:
            self.logger.error(f"Ошибка при генерации сигналов RSI: {e}")
            self.logger.debug(traceback.format_exc())
        
        return signals
    
    def _detect_divergences(self, df: pd.DataFrame, signals: List[Dict]) -> None:
        """
        Обнаруживает дивергенции между RSI и ценой.
        
        Args:
            df: DataFrame с данными и рассчитанным RSI
            signals: Список для добавления сигналов о дивергенциях
        """
        try:
            # Для обнаружения дивергенций нужно достаточное количество данных
            if len(df) < 20:
                return
            
            # Находим локальные экстремумы цены и RSI
            price_highs = argrelextrema(df['close'].values, np.greater, order=5)[0]
            price_lows = argrelextrema(df['close'].values, np.less, order=5)[0]
            rsi_highs = argrelextrema(df['rsi'].values, np.greater, order=5)[0]
            rsi_lows = argrelextrema(df['rsi'].values, np.less, order=5)[0]
            
            # Проверяем медвежьи дивергенции (цена растет, RSI падает)
            for i in range(1, min(len(price_highs), 10)):  # Ограничиваем 10 последними экстремумами
                if len(price_highs) <= i or price_highs[-i] >= len(df) - 5:
                    continue
                
                ph_current = price_highs[-i]
                
                # Ищем предыдущий ценовой максимум
                prev_ph = None
                for j in range(i+1, min(len(price_highs), i+5)):
                    if price_highs[-j] < ph_current - 3:  # минимальное расстояние между экстремумами
                        prev_ph = price_highs[-j]
                        break
                
                if prev_ph is None:
                    continue
                
                # Проверяем, растет ли цена и падает ли RSI
                if (df['close'].iloc[ph_current] > df['close'].iloc[prev_ph] and 
                    df['rsi'].iloc[ph_current] < df['rsi'].iloc[prev_ph]):
                    
                    # Вычисляем силу дивергенции
                    price_change = (df['close'].iloc[ph_current] / df['close'].iloc[prev_ph]) - 1
                    rsi_change = (df['rsi'].iloc[ph_current] / df['rsi'].iloc[prev_ph]) - 1
                    
                    # Если цена выросла значительно, а RSI снизился, это сильная медвежья дивергенция
                    if price_change > 0.01 and rsi_change < -0.05:
                        signals.append({
                            'indicator': 'RSI',
                            'signal_type': SignalType.SELL.value,
                            'timestamp': str(df.index[ph_current]) if not isinstance(df.index[ph_current], str) else df.index[ph_current],
                            'price': float(df['close'].iloc[ph_current]),
                            'strength': min(0.9, abs(price_change - rsi_change)),
                            'description': 'Медвежья дивергенция: цена растет, RSI падает',
                            'value': float(df['rsi'].iloc[ph_current]),
                            'divergence': {
                                'type': 'bearish',
                                'price_change': float(price_change),
                                'rsi_change': float(rsi_change),
                                'start_index': int(prev_ph),
                                'end_index': int(ph_current)
                            }
                        })
            
            # Проверяем бычьи дивергенции (цена падает, RSI растет)
            for i in range(1, min(len(price_lows), 10)):  # Ограничиваем 10 последними экстремумами
                if len(price_lows) <= i or price_lows[-i] >= len(df) - 5:
                    continue
                
                pl_current = price_lows[-i]
                
                # Ищем предыдущий ценовой минимум
                prev_pl = None
                for j in range(i+1, min(len(price_lows), i+5)):
                    if price_lows[-j] < pl_current - 3:  # минимальное расстояние между экстремумами
                        prev_pl = price_lows[-j]
                        break
                
                if prev_pl is None:
                    continue
                
                # Проверяем, падает ли цена и растет ли RSI
                if (df['close'].iloc[pl_current] < df['close'].iloc[prev_pl] and 
                    df['rsi'].iloc[pl_current] > df['rsi'].iloc[prev_pl]):
                    
                    # Вычисляем силу дивергенции
                    price_change = (df['close'].iloc[pl_current] / df['close'].iloc[prev_pl]) - 1
                    rsi_change = (df['rsi'].iloc[pl_current] / df['rsi'].iloc[prev_pl]) - 1
                    
                    # Если цена упала значительно, а RSI вырос, это сильная бычья дивергенция
                    if price_change < -0.01 and rsi_change > 0.05:
                        signals.append({
                            'indicator': 'RSI',
                            'signal_type': SignalType.BUY.value,
                            'timestamp': str(df.index[pl_current]) if not isinstance(df.index[pl_current], str) else df.index[pl_current],
                            'price': float(df['close'].iloc[pl_current]),
                            'strength': min(0.9, abs(price_change - rsi_change)),
                            'description': 'Бычья дивергенция: цена падает, RSI растет',
                            'value': float(df['rsi'].iloc[pl_current]),
                            'divergence': {
                                'type': 'bullish',
                                'price_change': float(price_change),
                                'rsi_change': float(rsi_change),
                                'start_index': int(prev_pl),
                                'end_index': int(pl_current)
                            }
                        })
        
        except Exception as e:
            self.logger.error(f"Ошибка при поиске дивергенций RSI: {e}")
            self.logger.debug(traceback.format_exc())
    
    def analyze_context(self, df: pd.DataFrame, timeframe: str) -> IndicatorAnalysisResult:
        """
        Выполняет контекстуальный анализ RSI на основе всей истории.
        
        Контекстуальный анализ включает:
        - Текущее положение RSI в историческом контексте (перцентили)
        - Анализ эффективности сигналов RSI в разных фазах рынка
        - Определение трендов RSI и их сравнение с ценовыми трендами
        - Рекомендации на основе исторической эффективности
        
        Args:
            df: DataFrame с данными и рассчитанным RSI
            timeframe: Таймфрейм анализа ('5m', '15m', '1h', и т.д.)
            
        Returns:
            IndicatorAnalysisResult с результатами анализа
        """

        start_time = time.time()
        self.logger.info(f"Начало контекстуального анализа RSI для таймфрейма {timeframe}")

        try:
            if 'rsi' not in df.columns or len(df) < 30:
                self.logger.warning(f"Недостаточно данных для контекстуального анализа RSI ({timeframe})")
                return IndicatorAnalysisResult(
                    indicator_name="RSI",
                    current_value=None,
                    historical_context={},
                    market_phases={},
                    signals=[],
                    statistics={},
                    recommendation=SignalType.NEUTRAL.value,
                    confidence=0.0,
                    metadata={"error": "Недостаточно данных для анализа"}
                )
            
            # Получаем текущее значение RSI
            current_rsi = float(df['rsi'].iloc[-1])
            
            # 1. Исторический контекст RSI
            historical_context = self._analyze_historical_context(df)
            
            # 2. Анализ по фазам рынка
            market_phases = self._analyze_market_phases(df)
            
            # 3. Генерация сигналов
            signals = self.generate_signals(df)
            
            # Фильтруем сигналы для последних N периодов
            recent_periods = min(20, len(df) // 10)  # ~10% от всей истории, но не более 20 периодов
            recent_signals = [s for s in signals if s['timestamp'] in df.index[-recent_periods:].astype(str)]
            
            # 4. Расчет статистики
            statistics = self._calculate_statistics(df)
            
            # 5. Формирование рекомендации
            recommendation, confidence = self._generate_recommendation(
                df, current_rsi, historical_context, market_phases, recent_signals
            )
            
            # Создаем результат анализа
            result = IndicatorAnalysisResult(
                indicator_name="RSI",
                current_value=current_rsi,
                historical_context=historical_context,
                market_phases=market_phases,
                signals=recent_signals,
                statistics=statistics,
                recommendation=recommendation,
                confidence=confidence,
                metadata={
                    "timeframe": timeframe,
                    "analysis_timestamp": datetime.now().isoformat(),
                    "symbol": getattr(df, 'symbol', 'unknown'),
                    "data_points": len(df),
                    "period": self.period
                }
            )
            
            self.logger.info(f"Завершение контекстуального анализа RSI. Результат: {recommendation}, уверенность: {confidence:.2f}")
            self.logger.debug(f"Контекстуальный анализ RSI занял {time.time() - start_time:.4f} секунд")

            return result
            
        except Exception as e:
            self.logger.error(f"Ошибка при контекстуальном анализе RSI: {e}")
            self.logger.debug(traceback.format_exc())
            
            # Возвращаем базовый результат с ошибкой
            return IndicatorAnalysisResult(
                indicator_name="RSI",
                current_value=None,
                historical_context={},
                market_phases={},
                signals=[],
                statistics={},
                recommendation=SignalType.NEUTRAL.value,
                confidence=0.0,
                metadata={"error": str(e)}
            )
    
    def _analyze_historical_context(self, df: pd.DataFrame) -> Dict:
        """
        Анализирует исторический контекст RSI.
        
        Args:
            df: DataFrame с данными и рассчитанным RSI
            
        Returns:
            Dict: Словарь с историческим контекстом
        """
        rsi_values = df['rsi'].dropna()
        current_rsi = rsi_values.iloc[-1]
        
        # Рассчитываем перцентили для текущего значения RSI
        percentile = stats.percentileofscore(rsi_values, current_rsi)
        
        # Анализируем исторические зоны перекупленности/перепроданности
        historical_overbought = rsi_values > self.overbought
        historical_oversold = rsi_values < self.oversold
        
        # Рассчитываем, сколько % времени RSI был в зонах перекупленности/перепроданности
        pct_overbought = historical_overbought.mean() * 100
        pct_oversold = historical_oversold.mean() * 100
        
        # Определяем исторические экстремумы
        rsi_max = rsi_values.max()
        rsi_min = rsi_values.min()
        
        # Определяем, как долго обычно RSI находится в зонах перекупленности/перепроданности
        if historical_overbought.any():
            overbought_durations = self._calculate_zone_durations(historical_overbought)
            avg_overbought_duration = np.mean(overbought_durations)
            max_overbought_duration = np.max(overbought_durations)
        else:
            avg_overbought_duration = 0
            max_overbought_duration = 0
            
        if historical_oversold.any():
            oversold_durations = self._calculate_zone_durations(historical_oversold)
            avg_oversold_duration = np.mean(oversold_durations)
            max_oversold_duration = np.max(oversold_durations)
        else:
            avg_oversold_duration = 0
            max_oversold_duration = 0
        
        # Анализируем, как быстро RSI обычно возвращается из зон экстремумов
        return_from_overbought = self._analyze_returns_from_zones(df, historical_overbought)
        return_from_oversold = self._analyze_returns_from_zones(df, historical_oversold)
        
        # Определяем адаптивные уровни на основе исторического распределения
        adaptive_overbought = np.percentile(rsi_values, 80)  # 80-й перцентиль
        adaptive_oversold = np.percentile(rsi_values, 20)    # 20-й перцентиль
        
        return {
            "current_percentile": percentile,
            "historical_max": float(rsi_max),
            "historical_min": float(rsi_min),
            "avg_value": float(rsi_values.mean()),
            "median_value": float(rsi_values.median()),
            "std_dev": float(rsi_values.std()),
            "percent_time_overbought": float(pct_overbought),
            "percent_time_oversold": float(pct_oversold),
            "avg_overbought_duration_periods": float(avg_overbought_duration),
            "max_overbought_duration_periods": float(max_overbought_duration),
            "avg_oversold_duration_periods": float(avg_oversold_duration),
            "max_oversold_duration_periods": float(max_oversold_duration),
            "avg_periods_to_return_from_overbought": float(return_from_overbought.get('avg_periods', 0)),
            "avg_periods_to_return_from_oversold": float(return_from_oversold.get('avg_periods', 0)),
            "adaptive_overbought_level": float(adaptive_overbought),
            "adaptive_oversold_level": float(adaptive_oversold)
        }
    
    def _calculate_zone_durations(self, zone_mask: pd.Series) -> List[int]:
        """
        Рассчитывает продолжительность пребывания RSI в определенной зоне.
        
        Args:
            zone_mask: Маска с True для периодов, когда RSI находится в зоне
            
        Returns:
            List[int]: Список продолжительностей пребывания в зоне (в периодах)
        """
        # Определяем границы зон (True/False)
        zone_starts = (zone_mask != zone_mask.shift(1)) & zone_mask
        zone_ends = (zone_mask != zone_mask.shift(-1)) & zone_mask
        
        # Получаем индексы начала и конца каждой зоны
        start_indices = zone_starts[zone_starts].index.tolist()
        end_indices = zone_ends[zone_ends].index.tolist()
        
        # Если количество начал и концов не совпадает, корректируем
        if len(start_indices) > len(end_indices):
            start_indices = start_indices[:len(end_indices)]
        elif len(end_indices) > len(start_indices):
            end_indices = end_indices[:len(start_indices)]
        
        # Рассчитываем продолжительность каждой зоны
        durations = []
        for i in range(len(start_indices)):
            start_idx = zone_mask.index.get_loc(start_indices[i])
            end_idx = zone_mask.index.get_loc(end_indices[i])
            duration = end_idx - start_idx + 1
            durations.append(duration)
        
        return durations if durations else [0]
    
    def _analyze_returns_from_zones(self, df: pd.DataFrame, zone_mask: pd.Series) -> Dict:
        """
        Анализирует, как быстро RSI возвращается из зоны перекупленности/перепроданности.
        
        Args:
            df: DataFrame с данными и рассчитанным RSI
            zone_mask: Маска с True для периодов, когда RSI находится в зоне
            
        Returns:
            Dict: Словарь с результатами анализа
        """
        if not zone_mask.any():
            return {"avg_periods": 0, "max_periods": 0, "min_periods": 0}
        
        # Находим выходы из зоны
        zone_exits = (zone_mask != zone_mask.shift(-1)) & zone_mask
        
        periods_to_return = []
        
        for idx in zone_exits[zone_exits].index:
            idx_pos = df.index.get_loc(idx)
            
            # Пропускаем, если это последний индекс
            if idx_pos >= len(df) - 1:
                continue
            
            # Определяем, в какую зону вышли (из перекупленности вниз или из перепроданности вверх)
            if df.loc[idx, 'rsi'] > 50:  # Выход из зоны перекупленности
                target = 50  # Цель - пересечение 50
            else:  # Выход из зоны перепроданности
                target = 50  # Цель - пересечение 50
            
            # Ищем, когда RSI достигнет целевого значения
            for i in range(idx_pos + 1, min(idx_pos + 50, len(df))):
                cross_down = df.iloc[i-1]['rsi'] > target and df.iloc[i]['rsi'] <= target
                cross_up = df.iloc[i-1]['rsi'] < target and df.iloc[i]['rsi'] >= target
                
                if cross_down or cross_up:
                    periods_to_return.append(i - idx_pos)
                    break
        
        if periods_to_return:
            return {
                "avg_periods": np.mean(periods_to_return),
                "max_periods": np.max(periods_to_return),
                "min_periods": np.min(periods_to_return)
            }
        else:
            return {"avg_periods": 0, "max_periods": 0, "min_periods": 0}
    
    def _analyze_market_phases(self, df: pd.DataFrame) -> Dict:
        """
        Анализирует поведение RSI в различных фазах рынка.
        
        Args:
            df: DataFrame с данными и рассчитанным RSI
            
        Returns:
            Dict: Словарь с результатами анализа по фазам рынка
        """
        results = {}
        
        # Для полноценного анализа фаз рынка нужно достаточное количество данных
        if len(df) < 50:
            return {"error": "Недостаточно данных для анализа фаз рынка"}
        
        # Разбиваем историю на сегменты (примерно по 20-30 баров)
        segment_size = min(30, max(20, len(df) // 10))
        segments = [df.iloc[i:i+segment_size] for i in range(0, len(df), segment_size)]
        
        # Анализируем каждый сегмент
        phase_data = defaultdict(list)
        
        for segment in segments:
            if len(segment) < 10:  # Пропускаем слишком короткие сегменты
                continue
                
            # Определяем фазу рынка для этого сегмента
            phase = self.detect_market_phase(segment)
            
            # Рассчитываем средние значения RSI для этой фазы
            avg_rsi = segment['rsi'].mean()
            
            # Рассчитываем эффективность сигналов RSI в этой фазе
            signals = self.generate_signals(segment)
            
            # Оцениваем результаты сигналов (просто оценка, без реального бэктеста)
            buy_success, sell_success = self._evaluate_signals_simple(segment, signals)
            
            # Добавляем данные для этой фазы
            phase_data[phase.value].append({
                "avg_rsi": float(avg_rsi),
                "signal_count": len(signals),
                "buy_success_rate": buy_success,
                "sell_success_rate": sell_success
            })
        
        # Агрегируем данные по фазам
        for phase, phase_segments in phase_data.items():
            if not phase_segments:
                continue
                
            avg_rsi_values = [seg["avg_rsi"] for seg in phase_segments]
            buy_success_rates = [seg["buy_success_rate"] for seg in phase_segments if seg["buy_success_rate"] is not None]
            sell_success_rates = [seg["sell_success_rate"] for seg in phase_segments if seg["sell_success_rate"] is not None]
            
            results[phase] = {
                "segment_count": len(phase_segments),
                "avg_rsi": np.mean(avg_rsi_values) if avg_rsi_values else None,
                "buy_success_rate": np.mean(buy_success_rates) if buy_success_rates else None,
                "sell_success_rate": np.mean(sell_success_rates) if sell_success_rates else None,
                "signal_count": sum(seg["signal_count"] for seg in phase_segments)
            }
        
        # Определяем текущую фазу рынка
        current_segment = df.iloc[-min(30, len(df)):]
        current_phase = self.detect_market_phase(current_segment).value
        
        results["current_phase"] = current_phase
        
        return results
    
    def _evaluate_signals_simple(self, df: pd.DataFrame, signals: List[Dict]) -> Tuple[Optional[float], Optional[float]]:
        """
        Простая оценка эффективности сигналов RSI без проведения полного бэктеста.
        
        Args:
            df: DataFrame с данными
            signals: Список сигналов
            
        Returns:
            Tuple[Optional[float], Optional[float]]: (процент успешных покупок, процент успешных продаж)
        """
        if not signals:
            return None, None
        
        buy_signals = [s for s in signals if s['signal_type'] == SignalType.BUY.value]
        sell_signals = [s for s in signals if s['signal_type'] == SignalType.SELL.value]
        
        if not buy_signals and not sell_signals:
            return None, None
        
        # Оцениваем успешность покупок (если цена выросла в течение N периодов после сигнала)
        buy_success_count = 0
        for signal in buy_signals:
            try:
                signal_idx = df.index.get_loc(pd.Timestamp(signal['timestamp']) if not isinstance(signal['timestamp'], str) else signal['timestamp'])
                
                # Пропускаем сигналы на границе данных
                if signal_idx >= len(df) - 5:
                    continue
                
                # Проверяем, выросла ли цена на 2% или более в течение 5 баров после сигнала
                entry_price = signal['price']
                future_prices = df['close'].iloc[signal_idx+1:min(signal_idx+6, len(df))]
                
                if len(future_prices) > 0:
                    max_price = future_prices.max()
                    if max_price / entry_price >= 1.02:  # 2% рост
                        buy_success_count += 1
            except Exception:
                continue
        
        # Оцениваем успешность продаж (если цена упала в течение N периодов после сигнала)
        sell_success_count = 0
        for signal in sell_signals:
            try:
                signal_idx = df.index.get_loc(pd.Timestamp(signal['timestamp']) if not isinstance(signal['timestamp'], str) else signal['timestamp'])
                
                # Пропускаем сигналы на границе данных
                if signal_idx >= len(df) - 5:
                    continue
                
                # Проверяем, упала ли цена на 2% или более в течение 5 баров после сигнала
                entry_price = signal['price']
                future_prices = df['close'].iloc[signal_idx+1:min(signal_idx+6, len(df))]
                
                if len(future_prices) > 0:
                    min_price = future_prices.min()
                    if entry_price / min_price >= 1.02:  # 2% падение
                        sell_success_count += 1
            except Exception:
                continue
        
        # Рассчитываем процент успешных сигналов
        buy_success_rate = buy_success_count / len(buy_signals) if buy_signals else None
        sell_success_rate = sell_success_count / len(sell_signals) if sell_signals else None
        
        return buy_success_rate, sell_success_rate
    
    def _calculate_statistics(self, df: pd.DataFrame) -> Dict:
        """
        Рассчитывает статистические метрики для RSI.
        
        Args:
            df: DataFrame с данными и рассчитанным RSI
            
        Returns:
            Dict: Словарь со статистикой
        """
        rsi_values = df['rsi'].dropna()
        
        if len(rsi_values) < 10:
            return {"error": "Недостаточно данных для расчета статистики"}
        
        # Рассчитываем базовые статистики
        stats_data = {
            "mean": float(rsi_values.mean()),
            "median": float(rsi_values.median()),
            "std_dev": float(rsi_values.std()),
            "min": float(rsi_values.min()),
            "max": float(rsi_values.max()),
            "skew": float(rsi_values.skew()),  # Асимметрия распределения
            "kurtosis": float(rsi_values.kurtosis()),  # Эксцесс распределения
            "histogram_bins": np.histogram(rsi_values, bins=10)[0].tolist()
        }
        
        # Рассчитываем автокорреляцию (для оценки цикличности)
        try:
            autocorr = pd.Series(rsi_values).autocorr(lag=7)  # Автокорреляция с лагом 7
            stats_data["autocorrelation_lag7"] = float(autocorr) if not np.isnan(autocorr) else 0
        except Exception:
            stats_data["autocorrelation_lag7"] = 0
        
        # Оцениваем тренд RSI
        recent_window = min(20, len(rsi_values) // 4)
        if recent_window > 0:
            recent_values = rsi_values.iloc[-recent_window:]
            if len(recent_values) > 1:
                slope, intercept, r_value, p_value, std_err = stats.linregress(range(len(recent_values)), recent_values)
                stats_data["recent_trend"] = {
                    "slope": float(slope),
                    "r_squared": float(r_value ** 2),
                    "p_value": float(p_value)
                }
        
        return stats_data
    
    def _generate_recommendation(self, df: pd.DataFrame, current_rsi: float, 
                                historical_context: Dict, market_phases: Dict, 
                                recent_signals: List[Dict]) -> Tuple[str, float]:
        """
        Генерирует рекомендацию на основе контекстуального анализа.
        
        Args:
            df: DataFrame с данными
            current_rsi: Текущее значение RSI
            historical_context: Исторический контекст
            market_phases: Анализ по фазам рынка
            recent_signals: Недавние сигналы
            
        Returns:
            Tuple[str, float]: (рекомендация, уверенность)
        """
        recommendation = SignalType.NEUTRAL.value
        base_confidence = 0.5
        confidence_adjustments = []
        
        # 1. Проверяем текущее положение RSI
        if current_rsi <= historical_context.get("adaptive_oversold_level", self.oversold):
            recommendation = SignalType.BUY.value
            confidence_adjustments.append(0.2)
            
            # Если RSI очень низкий (ниже исторического минимума + 5), повышаем уверенность
            if current_rsi < historical_context.get("historical_min", 0) + 5:
                confidence_adjustments.append(0.15)
                
        elif current_rsi >= historical_context.get("adaptive_overbought_level", self.overbought):
            recommendation = SignalType.SELL.value
            confidence_adjustments.append(0.2)
            
            # Если RSI очень высокий (выше исторического максимума - 5), повышаем уверенность
            if current_rsi > historical_context.get("historical_max", 100) - 5:
                confidence_adjustments.append(0.15)
        
        # 2. Учитываем недавние сигналы
        if recent_signals:
            # Фильтруем только самые свежие сигналы (последние 3 периода)
            latest_signals = [s for s in recent_signals 
                             if s['timestamp'] in df.index[-3:].astype(str)]
            
            if latest_signals:
                # Берем самый свежий сигнал
                latest_signal = latest_signals[-1]
                signal_type = latest_signal.get('signal_type')
                
                # Если текущая рекомендация совпадает с последним сигналом, повышаем уверенность
                if signal_type == recommendation:
                    confidence_adjustments.append(0.15)
                    
                    # Если сигнал основан на дивергенции, дополнительно повышаем уверенность
                    if 'divergence' in latest_signal:
                        confidence_adjustments.append(0.1)
                
                # Если текущая рекомендация противоречит последнему сигналу, снижаем уверенность
                elif signal_type != SignalType.NEUTRAL.value and signal_type != recommendation:
                    confidence_adjustments.append(-0.1)
        
        # 3. Учитываем текущую фазу рынка
        current_phase = market_phases.get("current_phase")
        if current_phase:
            phase_data = market_phases.get(current_phase, {})
            
            # Проверяем эффективность сигналов в текущей фазе рынка
            if recommendation == SignalType.BUY.value:
                success_rate = phase_data.get("buy_success_rate")
                if success_rate is not None:
                    confidence_adjustments.append((success_rate - 0.5) * 0.3)  # Корректируем на основе успешности
            
            elif recommendation == SignalType.SELL.value:
                success_rate = phase_data.get("sell_success_rate")
                if success_rate is not None:
                    confidence_adjustments.append((success_rate - 0.5) * 0.3)  # Корректируем на основе успешности
            
            # Корректируем рекомендацию на основе фазы рынка
            if current_phase == MarketPhase.UPTREND.value and recommendation == SignalType.SELL.value:
                confidence_adjustments.append(-0.1)  # Снижаем уверенность продажи в восходящем тренде
            
            elif current_phase == MarketPhase.DOWNTREND.value and recommendation == SignalType.BUY.value:
                confidence_adjustments.append(-0.1)  # Снижаем уверенность покупки в нисходящем тренде
        
        # 4. Учитываем положение RSI относительно центральной линии (50)
        if recommendation == SignalType.BUY.value and current_rsi > 50:
            confidence_adjustments.append(-0.1)  # Снижаем уверенность покупки, если RSI > 50
        
        elif recommendation == SignalType.SELL.value and current_rsi < 50:
            confidence_adjustments.append(-0.1)  # Снижаем уверенность продажи, если RSI < 50
        
        # 5. Учитываем скорость изменения RSI
        try:
            rsi_change = df['rsi_change'].iloc[-1]
            
            # Если RSI быстро растет и рекомендация покупать, повышаем уверенность
            if recommendation == SignalType.BUY.value and rsi_change > 5:
                confidence_adjustments.append(0.1)
            
            # Если RSI быстро падает и рекомендация продавать, повышаем уверенность
            elif recommendation == SignalType.SELL.value and rsi_change < -5:
                confidence_adjustments.append(0.1)
        except Exception:
            pass
        
        # Применяем корректировки к базовой уверенности
        final_confidence = base_confidence
        for adjustment in confidence_adjustments:
            final_confidence += adjustment
        
        # Ограничиваем уверенность в диапазоне [0.1, 0.95]
        final_confidence = max(0.1, min(0.95, final_confidence))
        
        # Если уверенность очень низкая, считаем рекомендацию нейтральной
        if final_confidence < 0.3:
            recommendation = SignalType.NEUTRAL.value
            final_confidence = 0.5  # Сбрасываем уверенность до базовой
        
        # Если рекомендация нейтральная, снижаем уверенность
        if recommendation == SignalType.NEUTRAL.value:
            final_confidence = 0.5
        
        return recommendation, final_confidence


# ============================================================
# УПРАВЛЯЮЩИЙ КЛАСС INDICATOR ENGINE
# ============================================================

class IndicatorEngine:
    """
    Основной класс для управления анализом индикаторов.
    
    Координирует работу всех компонентов: загрузку данных, расчет индикаторов,
    анализ исторических данных, и формирование результатов.
    
    Функционирует как конструктор, позволяющий добавлять новые индикаторы без
    переписывания кода.
    """
    
    def __init__(self, config: Dict):
        """
        Инициализирует движок индикаторов.
        
        Args:
            config: Словарь с конфигурацией движка
        """
        self.config = config
        self.logger = get_clean_logger("indicator_engine")
        self.logger.info("Инициализация IndicatorEngine")
        
        # Инициализация утилит и хелперов
        self.data_cache = DataCache(
            use_redis=config.get('use_redis', False),
            redis_config=config.get('redis_config')
        )
        
        self.data_storage = DataStorage(
            base_path=config['paths'].get('BRAIN_DATA', 'data/brain/'),
            use_parquet=config.get('use_parquet', False)
        )
        
        self.parallel_processor = ParallelProcessor(
            max_workers=config['processing'].get('max_workers', 8),
            chunk_size=config['processing'].get('batch_size', 10)
        )
        
        # Инициализация реестра индикаторов
        self.indicator_registry = IndicatorRegistry()
        
        # Регистрация индикаторов
        self._register_indicators()
        
        self.logger.info(f"IndicatorEngine инициализирован с {len(self.indicator_registry.get_all())} индикаторами")
    
    def _register_indicators(self) -> None:
        """
        Регистрирует индикаторы в реестре согласно конфигурации.
        
        Это место, где добавляются новые индикаторы при расширении системы.
        """
        # Регистрация RSI
        rsi_enabled = self.config.get('indicators', {}).get('phase1', {}).get('momentum', {}).get('RSI', {}).get('enabled', True)
        if rsi_enabled:
            rsi_params = self.config.get('indicators', {}).get('phase1', {}).get('momentum', {}).get('RSI', {})
            self.indicator_registry.register(RSI, "RSI", params=rsi_params)
            self.logger.info("RSI индикатор зарегистрирован")
        
        # Здесь можно добавить другие индикаторы по мере их разработки
        # Например:
        # macd_enabled = self.config.get('indicators', {}).get('phase1', {}).get('trend', {}).get('MACD', {}).get('enabled', True)
        # if macd_enabled:
        #     macd_params = self.config.get('indicators', {}).get('phase1', {}).get('trend', {}).get('MACD', {})
        #     self.indicator_registry.register(MACD, "MACD", params=macd_params)
    
    def register_indicator(self, indicator_class: type, name: str = None, params: Dict = None) -> None:
        """
        Регистрирует новый индикатор в системе (внешний интерфейс).
        
        Args:
            indicator_class: Класс индикатора
            name: Имя для регистрации (если None, используется имя класса)
            params: Параметры для инициализации индикатора
        """
        self.indicator_registry.register(indicator_class, name, params)
    
    def load_data(self, symbol: str, timeframe: str) -> Optional[pd.DataFrame]:
        """
        Загружает данные для указанного символа и таймфрейма.
        
        Args:
            symbol: Символ монеты
            timeframe: Таймфрейм
            
        Returns:
            DataFrame с данными или None, если данные не найдены
        """

        start_time = time.time()

        try:
            # Базовая директория с данными
            base_path = os.path.join(self.config['paths'].get('DATA_ENGINE', {}).get('current', 'data/brain/data_engine/current'), timeframe)
            
            # Попробуем разные варианты имен файлов
            json_paths = [
                os.path.join(base_path, f"{symbol}_{timeframe}.json"),
                os.path.join(base_path, f"{symbol}.json"),
                os.path.join(self.config['paths'].get('DATA_ENGINE', {}).get('current', 'data/brain/data_engine/current'), f"{symbol}_{timeframe}.json"),
                os.path.join(self.config['paths'].get('DATA_ENGINE', {}).get('current', 'data/brain/data_engine/current'), f"{symbol}.json")
            ]
            
            # Для отладки выведем все проверяемые пути
            self.logger.debug(f"Ищем данные для {symbol} ({timeframe}) в путях: {json_paths}")
            
            # Ищем первый существующий файл
            json_path = None
            for path in json_paths:
                if os.path.exists(path):
                    json_path = path
                    self.logger.debug(f"Найден файл данных: {path}")
                    break
            
            if not json_path:
                self.logger.warning(f"Файлы с данными не найдены для {symbol} ({timeframe})")
                return None
            
            # Загружаем JSON данные
            self.logger.info(f"Загружаем данные из JSON: {json_path}")
            with open(json_path, 'r') as f:
                data = json.load(f)
            
            # Вывод первых нескольких элементов для отладки
            self.logger.debug(f"Первые 3 элемента JSON: {json.dumps(data[:3] if len(data) > 3 else data, indent=2)}")
            
            # Преобразуем специфический формат JSON в DataFrame
            rows = []
            for candle in data:
                # Проверяем наличие необходимых ключей
                if 'quote' not in candle or 'USD' not in candle['quote']:
                    continue
                    
                # Получаем данные свечи
                quote = candle['quote']['USD']
                
                # Создаем запись для DataFrame
                row = {
                    'timestamp': quote.get('timestamp', candle.get('time_close')),
                    'open': quote.get('open', 0.0),
                    'high': quote.get('high', 0.0),
                    'low': quote.get('low', 0.0),
                    'close': quote.get('close', 0.0),
                    'volume': quote.get('volume', 0.0)
                }
                
                rows.append(row)
            
            # Если нет данных, возвращаем None
            if not rows:
                self.logger.warning(f"В JSON файле не найдено данных в ожидаемом формате для {symbol} ({timeframe})")
                return None
            
            # Создаем DataFrame
            df = pd.DataFrame(rows)
            
            # Преобразуем timestamp в datetime и устанавливаем как индекс
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df.set_index('timestamp', inplace=True)
            
            # Сортируем по индексу (времени)
            df.sort_index(inplace=True)
            
            # Добавляем атрибут с символом монеты
            df.symbol = symbol
            
            # После загрузки данных добавляем расширенную информацию
            if len(df) > 0:
                self.logger.info(f"Данные загружены успешно: {len(df)} строк, столбцы: {list(df.columns)}")
                self.logger.debug(f"Первые 3 строки данных:\n{df.head(3)}")
                self.logger.debug(f"Загрузка данных для {symbol} ({timeframe}) заняла {time.time() - start_time:.4f} секунд")
            
            return df
                
        except Exception as e:
            self.logger.error(f"Ошибка при загрузке данных для {symbol} ({timeframe}): {e}")
            self.logger.debug(traceback.format_exc())
            return None
    
    def analyze_indicator(self, indicator_name: str, df: pd.DataFrame, timeframe: str) -> Dict:
        """
        Анализирует данные с использованием указанного индикатора.
        
        Args:
            indicator_name: Имя индикатора
            df: DataFrame с данными
            timeframe: Таймфрейм
            
        Returns:
            Словарь с результатами анализа
        """
        indicator = self.indicator_registry.get(indicator_name)
        if not indicator:
            return {
                'success': False,
                'error': f"Индикатор {indicator_name} не зарегистрирован"
            }
        
        try:
            # Рассчитываем индикатор
            df_with_indicator = indicator.calculate(df.copy())
            
            # Проводим контекстуальный анализ
            analysis_result = indicator.analyze_context(df_with_indicator, timeframe)
            
            return {
                'success': True,
                'indicator_name': indicator_name,
                'symbol': getattr(df, 'symbol', 'unknown'),
                'timeframe': timeframe,
                'result': analysis_result._asdict(),
                'data_points': len(df)
            }
        except Exception as e:
            self.logger.error(f"Ошибка при анализе индикатора {indicator_name}: {e}")
            self.logger.debug(traceback.format_exc())
            return {
                'success': False,
                'error': str(e),
                'indicator_name': indicator_name,
                'symbol': getattr(df, 'symbol', 'unknown'),
                'timeframe': timeframe
            }
    
    def analyze_timeframe(self, symbol: str, timeframe: str, indicator_list: List[str] = None) -> Dict:
        """
        Анализирует данные для указанного символа и таймфрейма с использованием всех индикаторов.
        
        Args:
            symbol: Символ монеты
            timeframe: Таймфрейм
            indicator_list: Список индикаторов для расчета (если None, используются все доступные)
            
        Returns:
            Словарь с результатами анализа
        """
        start_time = time.time()
        
        try:
            # Загружаем данные
            df = self.load_data(symbol, timeframe)
            if df is None:
                return {
                    'success': False, 
                    'error': 'Не удалось загрузить данные',
                    'symbol': symbol,
                    'timeframe': timeframe
                }
            
            # Если список индикаторов не указан, используем все доступные
            if indicator_list is None:
                indicator_list = list(self.indicator_registry.get_all().keys())
            
            # Анализируем каждый индикатор
            results = {}
            for indicator_name in indicator_list:
                if self.indicator_registry.has_indicator(indicator_name):
                    indicator_result = self.analyze_indicator(indicator_name, df, timeframe)
                    results[indicator_name] = indicator_result
                else:
                    self.logger.warning(f"Индикатор {indicator_name} не найден. Пропускаем.")
            
            execution_time = time.time() - start_time
            
            # Формируем результат
            return {
                'success': True,
                'symbol': symbol,
                'timeframe': timeframe,
                'indicators': results,
                'data_points': len(df) if df is not None else 0,
                'execution_time': execution_time
            }
        except Exception as e:
            self.logger.error(f"Ошибка при анализе {symbol} ({timeframe}): {e}")
            self.logger.debug(traceback.format_exc())
            
            execution_time = time.time() - start_time
            
            return {
                'success': False,
                'error': str(e),
                'symbol': symbol,
                'timeframe': timeframe,
                'execution_time': execution_time
            }
    
    def analyze_symbol(self, symbol: str, timeframes: List[str] = None) -> Dict:
        """
        Анализирует данные для указанного символа по всем таймфреймам.
        
        Args:
            symbol: Символ монеты
            timeframes: Список таймфреймов для анализа (если None, используются все доступные)
            
        Returns:
            Словарь с результатами анализа
        """
        start_time = time.time()
        
        self.logger.info(f"=== Начало анализа монеты {symbol} ===")

        try:
            # Если таймфреймы не указаны, используем все доступные из конфигурации
            if timeframes is None:
                timeframes = [tf for tf, config in self.config.get('TIMEFRAMES', {}).items() 
                             if config.get('enabled', True)]
            
            # Разделяем таймфреймы на важные и вторичные
            primary_timeframes = [tf for tf in timeframes if tf in ['7d', '24h', '4h', '1h']]
            secondary_timeframes = [tf for tf in timeframes if tf in ['30m', '15m', '5m']]
            
            results = {}
            signals_by_tf = {}
            
            # Сначала анализируем основные таймфреймы
            for tf in primary_timeframes:
                result = self.analyze_timeframe(symbol, tf)
                if result['success']:
                    results[tf] = result
                    
                    # Сохраняем результаты анализа
                    self.data_storage.save_indicators(symbol, tf, result)
                    self.logger.info(f"Результаты индикаторов для {symbol} ({tf}) сохранены")
            
            # Определяем, нужно ли анализировать вторичные таймфреймы
            analyze_secondary = self._should_analyze_secondary_timeframes(symbol, results)
            
            # Если нужно, анализируем вторичные таймфреймы
            if analyze_secondary and secondary_timeframes:
                for tf in secondary_timeframes:
                    result = self.analyze_timeframe(symbol, tf)
                    if result['success']:
                        results[tf] = result
                        
                        # Сохраняем результаты анализа
                        self.data_storage.save_indicators(symbol, tf, result)
                        self.logger.info(f"Результаты индикаторов для {symbol} ({tf}) сохранены")
            
            # Определяем сводный сигнал по всем таймфреймам
            overall_signal = self._determine_overall_signal(results)
            
            self.logger.info(f"=== Завершение анализа монеты {symbol} ===")

            execution_time = time.time() - start_time
            
            return {
                'success': True,
                'symbol': symbol,
                'results': results,
                'overall_signal': overall_signal,
                'analyzed_timeframes': list(results.keys()),
                'execution_time': execution_time,
                'secondary_timeframes_analyzed': analyze_secondary
            }
            
        except Exception as e:
            self.logger.error(f"Ошибка при анализе символа {symbol}: {e}")
            self.logger.debug(traceback.format_exc())

            execution_time = time.time() - start_time
            
            return {
                'success': False,
                'error': str(e),
                'symbol': symbol,
                'execution_time': execution_time
            }
    
    def _should_analyze_secondary_timeframes(self, symbol: str, primary_results: Dict) -> bool:
        """
        Определяет, нужно ли анализировать вторичные таймфреймы.
        
        Вторичные таймфреймы анализируются, если на первичных таймфреймах наблюдается
        восходящий тренд или потенциально прибыльная ситуация.
        
        Args:
            symbol: Символ монеты
            primary_results: Результаты анализа первичных таймфреймов
            
        Returns:
            True если нужно анализировать вторичные таймфреймы, иначе False
        """
        # Для тестирования просто вернем True
        if self.config.get('testing', {}).get('enabled', False):
            return True
        
        # Проверяем результаты по каждому таймфрейму
        buy_signals_count = 0
        analyzed_count = 0
        
        for tf, result in primary_results.items():
            if not result.get('success', False):
                continue
                
            analyzed_count += 1
            
            # Проверяем каждый индикатор
            for indicator_name, indicator_result in result.get('indicators', {}).items():
                if not indicator_result.get('success', False):
                    continue
                    
                indicator_data = indicator_result.get('result', {})
                recommendation = indicator_data.get('recommendation')
                
                if recommendation == SignalType.BUY.value or recommendation == SignalType.STRONG_BUY.value:
                    buy_signals_count += 1
        
        # Если проанализировано менее 2 таймфреймов, анализируем вторичные
        if analyzed_count < 2:
            return True
        
        # Если более 50% индикаторов дают сигнал на покупку, анализируем вторичные
        return buy_signals_count / analyzed_count >= 0.5
    
    def _determine_overall_signal(self, results: Dict) -> Dict:
        """
        Определяет общий сигнал на основе результатов анализа всех таймфреймов.
        
        Args:
            results: Словарь с результатами анализа по таймфреймам
            
        Returns:
            Словарь с общим сигналом
        """
        # Весовые коэффициенты для разных таймфреймов
        tf_weights = {
            '7d': 0.1,   # 10%
            '24h': 0.3,  # 30%
            '4h': 0.3,   # 30%
            '1h': 0.3,   # 30%
            '30m': 0.0,  # Вторичные таймфреймы не учитываются в общей оценке
            '15m': 0.0,
            '5m': 0.0
        }
        
        buy_score = 0.0
        sell_score = 0.0
        neutral_score = 0.0
        weight_sum = 0.0
        
        for tf, result in results.items():
            if not result.get('success', False):
                continue
                
            tf_weight = tf_weights.get(tf, 0.0)
            
            # Суммируем оценки по всем индикаторам
            for indicator_name, indicator_result in result.get('indicators', {}).items():
                if not indicator_result.get('success', False):
                    continue
                    
                indicator_data = indicator_result.get('result', {})
                recommendation = indicator_data.get('recommendation')
                confidence = indicator_data.get('confidence', 0.5)
                
                # Взвешиваем рекомендацию в зависимости от уверенности
                if recommendation == SignalType.BUY.value or recommendation == SignalType.STRONG_BUY.value:
                    buy_score += confidence * tf_weight
                elif recommendation == SignalType.SELL.value or recommendation == SignalType.STRONG_SELL.value:
                    sell_score += confidence * tf_weight
                else:
                    neutral_score += tf_weight
                
                weight_sum += tf_weight
        
        # Если нет данных, возвращаем нейтральный сигнал
        if weight_sum == 0:
            return {
                'signal': SignalType.NEUTRAL.value,
                'buy_score': 0.0,
                'sell_score': 0.0,
                'neutral_score': 1.0,
                'confidence': 0.5
            }
        
        # Нормализуем оценки
        buy_score /= weight_sum
        sell_score /= weight_sum
        neutral_score /= weight_sum
        
        # Определяем итоговый сигнал
        if buy_score > sell_score and buy_score > neutral_score and buy_score > 0.6:
            signal = SignalType.BUY.value
            confidence = buy_score
        elif sell_score > buy_score and sell_score > neutral_score and sell_score > 0.6:
            signal = SignalType.SELL.value
            confidence = sell_score
        else:
            signal = SignalType.NEUTRAL.value
            confidence = max(0.5, max(buy_score, sell_score))
        
        return {
            'signal': signal,
            'buy_score': round(buy_score, 2),
            'sell_score': round(sell_score, 2),
            'neutral_score': round(neutral_score, 2),
            'confidence': round(confidence, 2)
        }
    
    def process_symbols(self, symbols: List[str], timeframes: List[str] = None) -> Dict:
        """
        Обрабатывает список символов параллельно.
        
        Args:
            symbols: Список символов для обработки
            timeframes: Список таймфреймов для анализа (если None, используются все доступные)
            
        Returns:
            Словарь с результатами обработки
        """
        def process_symbol_batch(symbol_batch):
            batch_results = {
                'successful_symbols': 0,
                'failed_symbols': 0,
                'results': {}
            }
            
            for symbol in symbol_batch:
                try:
                    result = self.analyze_symbol(symbol, timeframes)
                    batch_results['results'][symbol] = result
                    
                    if result.get('success', False):
                        batch_results['successful_symbols'] += 1
                    else:
                        batch_results['failed_symbols'] += 1
                except Exception as e:
                    self.logger.error(f"Ошибка при обработке символа {symbol}: {e}")
                    self.logger.debug(traceback.format_exc())
                    batch_results['failed_symbols'] += 1
            
            return batch_results
        
        # Обрабатываем символы параллельно
        results = self.parallel_processor.process_symbols(symbols, process_symbol_batch)
        
        # Находим топ символы на основе сигналов
        top_symbols = self._get_top_symbols(results.get('results', {}))
        results['top_symbols'] = top_symbols
        
        return results
    
    def _get_top_symbols(self, results: Dict, limit: int = 10) -> List[Dict]:
        """
        Находит топ символы на основе результатов анализа.
        
        Args:
            results: Словарь с результатами анализа по символам
            limit: Максимальное количество символов в результате
            
        Returns:
            Список словарей с информацией о топ символах
        """
        symbols_data = []
        
        for symbol, result in results.items():
            if not result.get('success', False):
                continue
                
            overall_signal = result.get('overall_signal', {})
            signal = overall_signal.get('signal', SignalType.NEUTRAL.value)
            confidence = overall_signal.get('confidence', 0.0)
            
            # Отбираем только символы с сигналом покупки и высокой уверенностью
            if signal == SignalType.BUY.value and confidence >= 0.7:
                symbols_data.append({
                    'symbol': symbol,
                    'signal': signal,
                    'confidence': confidence,
                    'buy_score': overall_signal.get('buy_score', 0.0),
                    'timeframes': result.get('analyzed_timeframes', [])
                })
        
        confidence_threshold = 0.7  # Это стандартный порог, используемый в коде
        self.logger.info(f"Порог уверенности для топовых монет: {confidence_threshold}. Найдено монет выше порога: {len(symbols_data)}")

        # Сортируем по уверенности (от высокой к низкой)
        symbols_data.sort(key=lambda x: x['confidence'], reverse=True)
        
        # Ограничиваем количество символов
        return symbols_data[:limit]
    
    def run(self, symbols: List[str] = None, timeframes: List[str] = None) -> Dict:
        """
        Запускает полный процесс анализа индикаторов.
        
        Args:
            symbols: Список символов для анализа (если None, будет загружен из данных)
            timeframes: Список таймфреймов для анализа (если None, используются все доступные)
            
        Returns:
            Словарь с результатами анализа
        """
        self.logger.info("Запуск полного анализа индикаторов")
        start_time = time.time()
        
        # Если символы не указаны, загружаем их
        if symbols is None:
            symbols = self._load_symbols()
            self.logger.info(f"Загружено {len(symbols)} символов для анализа")
        
        # Если таймфреймы не указаны, используем все доступные
        if timeframes is None:
            timeframes = [tf for tf, config in self.config.get('TIMEFRAMES', {}).items() 
                         if config.get('enabled', True)]
            self.logger.info(f"Используем таймфреймы: {', '.join(timeframes)}")
        
        # Запускаем процесс обработки
        results = self.process_symbols(symbols, timeframes)
        
        execution_time = time.time() - start_time
        results['execution_time'] = execution_time
        
        # Логируем результаты
        self.logger.info(f"Анализ завершен за {execution_time:.2f} сек. "
                         f"Успешно: {results.get('successful_symbols', 0)}/{len(symbols)} символов")
        
        # Отправляем уведомление в Telegram, если включено
        if self.config.get('telegram', {}).get('enabled', False):
            self._send_telegram_notification(results)
        
        return results
    
    def _load_symbols(self) -> List[str]:
        """
        Загружает список символов для анализа.
        
        Returns:
            Список символов
        """
        # Для тестирования или если указан фиксированный список символов в конфигурации
        if self.config.get('testing', {}).get('enabled', False):
            return self.config.get('testing', {}).get('symbols', ['BTC', 'ETH', 'BNB', 'SOL', 'XRP'])
        
        symbols = []
        
        try:
            # Определяем директорию с данными для основного таймфрейма
            main_timeframe = '1h'
            data_dir = os.path.join(self.config['paths'].get('DATA_ENGINE', {}).get('current', 'data/brain/data_engine/current'), main_timeframe)
            
            # Проверяем наличие директории
            if not os.path.exists(data_dir):
                self.logger.warning(f"Директория с данными не найдена: {data_dir}")
                return ['BTC', 'ETH', 'BNB', 'SOL', 'XRP']  # Возвращаем базовый список
            
            # Сканируем директорию и извлекаем символы из имен файлов
            for filename in os.listdir(data_dir):
                if filename.endswith('.json'):
                    symbol = filename.split('_')[0]
                    symbols.append(symbol)
            
            self.logger.info(f"Загружено {len(symbols)} символов из директории {data_dir}")
            
        except Exception as e:
            self.logger.error(f"Ошибка при загрузке списка символов: {e}")
            self.logger.debug(traceback.format_exc())
            return ['BTC', 'ETH', 'BNB', 'SOL', 'XRP']  # Возвращаем базовый список в случае ошибки
        
        # Если список пуст, возвращаем базовый список
        if not symbols:
            self.logger.warning("Список символов пуст. Используем базовый список.")
            return ['BTC', 'ETH', 'BNB', 'SOL', 'XRP']
        
        return symbols
    
    def _send_telegram_notification(self, results: Dict) -> None:
        """
        Отправляет уведомление в Telegram с результатами анализа.
        
        Args:
            results: Словарь с результатами анализа
        """
        try:
            # Формируем сообщение
            top_symbols = results.get('top_symbols', [])
            
            message_parts = [
                "📊 *Анализ индикаторов завершен*",
                f"⏱️ Время выполнения: {results.get('execution_time', 0):.2f} сек",
                f"✅ Успешно обработано: {results.get('successful_symbols', 0)}/{results.get('total_symbols', 0)} монет",
                f"📈 Найдено потенциальных монет: {len(top_symbols)}"
            ]
            
            # Добавляем информацию о топ символах
            if top_symbols:
                message_parts.append("\n*Топ монеты:*")
                for i, symbol_data in enumerate(top_symbols[:5], 1):  # Ограничиваем 5 монетами
                    message_parts.append(
                        f"{i}. *{symbol_data['symbol']}* - "
                        f"Уверенность: {symbol_data['confidence']:.2f}, "
                        f"Сигнал: {symbol_data['signal']}"
                    )
            
            message = "\n".join(message_parts)
            
            # Отправляем сообщение
            send_telegram(message, priority="normal")
            self.logger.info("Уведомление в Telegram отправлено")
            
        except Exception as e:
            self.logger.error(f"Ошибка при отправке уведомления в Telegram: {e}")
            self.logger.debug(traceback.format_exc())


# ============================================================
# ФУНКЦИЯ ТЕСТИРОВАНИЯ
# ============================================================

def test_indicator_engine():
    """
    Запускает тестовый анализ индикаторов.
    """
    logger.info("Запуск тестового анализа индикаторов")
    
    # Загружаем конфигурацию для IndicatorEngine
    config = {
        'paths': PATHS,
        'TIMEFRAMES': TIMEFRAMES,
        'processing': PROCESSING,
        'indicators': INDICATORS,
        'testing': {
            'enabled': True,
            'symbols': ['BTC', 'ETH', 'BNB', 'SOL', 'XRP']
        },
        'telegram': {
            'enabled': False  # Отключаем для тестирования
        }
    }
    
    # Создаем экземпляр IndicatorEngine
    engine = IndicatorEngine(config)
    
    # Тестовые монеты
    test_symbols = ['BTC', 'ETH']
    
    # Ограничиваем таймфреймы для тестирования
    test_timeframes = ['1h']
    
    # Запускаем анализ
    results = engine.run(test_symbols, test_timeframes)
    
    # Выводим результаты
    logger.info(f"Тестовый анализ завершен. Успешно обработано: {results.get('successful_symbols', 0)}/{len(test_symbols)} монет")
    
    # Проверяем топ символы
    top_symbols = results.get('top_symbols', [])
    if top_symbols:
        logger.info(f"Топ символы: {', '.join([s['symbol'] for s in top_symbols])}")
    else:
        logger.info("Топ символы не найдены")
    
    return results


if __name__ == "__main__":
    print("Запуск тестового анализа индикаторов")
    
    # Создаем директории, если они не существуют
    indicators_dir = os.path.join(PATHS.get('BRAIN_DATA', 'data/brain/'), "indicators", "current", "1h")
    os.makedirs(indicators_dir, exist_ok=True)
    
    # Запускаем тест
    test_results = test_indicator_engine()
    
    print("Тестовый анализ завершен")
